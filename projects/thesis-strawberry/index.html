<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Thesis Summary · Exploring Unsupervised Autoencoders for Early Disease Detection</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;600;800&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="../../assets/css/styles.css" />

</head>
<body>

<nav class="nav">
  <a class="brand" href="../../">Leon Weiser</a>
  <div class="links">
    <a href="../../#panel-about">About</a>
    <a href="../../#panel-posts">Posts</a>
    <a href="../../#panel-projects">Projects</a>
    <a href="https://github.com/Leowiser">GitHub</a>
  </div>
</nav>


<!-- New, simpler hero that just sits under the header -->
<!--<section class="page-hero">
  <h1 class="page-hero__title">Exploring Fully Unsupervised Autoencoders for Early Disease Detection</h1>
  <p class="page-hero__sub">Hyperspectral imaging of strawberry leaves to detect <em>P. cactorum</em>—no labels,
      anomaly detection via reconstruction error.</p>
  <a class="cta" href="https://github.com/Leowiser/Thesis_Strawberries">Code found on GitHub here.</a>
</section> -->
<section class="hero hero-static">
  <div class="text">
    <h1 class="hero-title">Exploring Fully Unsupervised Autoencoders for Early Disease Detection</h1>
    <p class="sub">Hyperspectral imaging of strawberry leaves to detect <em>P. cactorum</em>—no labels,
      anomaly detection via reconstruction error.</p>
    <div class="ctas">
      <a class="cta" href="https://github.com/Leowiser/Thesis_Strawberries">Code found on GitHub here.</a>
      <a class="cta" href="https://repository.teneo.libis.be/delivery/DeliveryManagerServlet?dps_pid=IE48017380&">Full Thesis.</a>
    </div>
  </div>
</section>

    <div class="grid">
      <section class="panel">
        <h2>Core Idea</h2>
        <ul>
          <li>Use hyperspectral images (≈398–1000&nbsp;nm) of strawberry leaves; train only on healthy leaves; flag anomalies via reconstruction errors from convolutional autoencoders (2D &amp; 3D).</li>
        </ul>
        <div class="fig-row">
          <figure class="figure-snug">
            <img src="../../assets/img/thesis/Cropped_preprocess.png" alt="Hyperspectral plant to leaf example">
            <figcaption>Cropped leaves from plant image.</figcaption>
          </figure>
          <figure class="figure-snug">
            <img src="../../assets/img/thesis/HSI_example.png" alt="Hyperspectral image and spectra">
            <figcaption>Example of hyperspectral leaf image and its spectra.</figcaption>
          </figure>
        </div>

        <h2>Data &amp; Preprocessing</h2>
        <ul>
          <li>20 plants imaged daily (~2 weeks), cropped to leaves; 388 samples (321 healthy / 67 infected).</li>
          <li>Preprocessing: mask background; remove noisy bands (&lt;430&nbsp;nm); SNV normalization; PCA-guided band selection to 17 wavelengths (also compared with full spectrum).</li>
        </ul>
        <div class="fig-row">
          <figure class="figure-snug">
            <img src="../../assets/img/thesis/Mask_preprocess.png" alt="Masked image example">
            <figcaption>Masked image.</figcaption>
          </figure>
          <figure class="figure-snug">
            <img src="../../assets/img/thesis/PCA_bandselect.png" alt="Hyperspectral plant to leaf example">
            <figcaption>Selected bands based on PCA loadings and spectral data exploration.</figcaption>
          </figure>
        </div>

        <h2>Method</h2>
        <ul>
          <li>Train <strong>3D Convolutional Autoencoder</strong> on healthy leaves; evaluate infection by image-level reconstruction error with thresholds; metrics: ROC-AUC, PR-AUC, FPR@95%TPR.</li>
          <li>Error-mitigation steps: remove edge artifacts, apply masks post-recon, prefer SNV to reduce illumination scatter.</li>
          <li>Experimented with alternative error metrics (e.g., per-band extreme-pixel rate; vein-focused errors; latent-space similarity).</li>
        </ul>
        <div class="fig-row">
          <figure class="figure-snug">
            <img src="../../assets/img/thesis/Vis_3DCNN.png" alt="Vis of 3DCAE">
            <figcaption>Visualization of 3D Convolutional Autoencoder.</figcaption>
          </figure>
          <figure class="figure-snug">
            <img src="../../assets/img/thesis/Recon_Error_Max.png" alt="Reconstruction error">
            <figcaption>Examplary leaf with reconstruction and mean absolute reconstruction error.</figcaption>
          </figure>
        </div>

        <h4>Alternative Error Metrics</h4>
        <ul>
          <li>Latent space similarity based on <a href="https://link.springer.com/article/10.1186/s13362-023-00133-6">Benfenati et al. (2023)</a>.</li>
          <li>Per-band extreme-error pixel: Own idea, using the rate of all pixels with error values above the 99&percnt; quantile of the validation set (only healthy leaves) over all pixels to identify diseases.</li>
          <li>Vein-focused errors: Original idea based on the disease spread in the plant, as it often progresses through the veins. Veins and proximate areas are identified using the highest eigenvalues. The mean absolute error of the found area is taken.</li>
        </ul>
        <div class="fig-row">
        <figure class="figure-snug">
          <img src="../../assets/img/thesis/Pixel_errors_99quant.png" alt="Extreme pixel error">
          <figcaption>Extreme-error pixels of leaves at different stages of infection and different bands. Pixels with errors above 99&percnt; are coloured red.</figcaption>
        </figure>
        <figure class="figure-snug">
          <img src="../../assets/img/thesis/Vein_Error.png" alt="Vein error">
          <figcaption>Identified veins and the error in that area for different stages of infection.</figcaption>
        </figure>
        </div>

        <h2>Key Findings</h2>
        <ul>
          <li>Fully unsupervised CAEs struggled to cleanly separate healthy vs infected leaves—especially in early stages; best conventional setup reached modest ROC-AUC, and 3D did not clearly outperform 2D.</li>
          <li>“Extreme-pixel” per-band metric showed most promise for day-1 infections (lowest FPR@95%TPR among tested metrics), but overall accuracy remained limited.</li>
          <li>Reduced 17-band sets performed comparably to the full spectrum → careful band selection can cut complexity without large losses.</li>
        </ul>

        <h2>Takeaways</h2>
        <ul>
          <li>Symptoms of <em>P. cactorum</em> resemble benign variation (e.g., drought stress), making purely unsupervised detection intrinsically hard on this dataset.</li>
          <li>Pipeline + preprocessing + error-metric ideas form a reusable baseline for future semi-supervised or hybrid approaches.</li>
        </ul>
      </section>
    </div>

    <footer>
      © <span id="year"></span> Leon Weiser
    </footer>
  </div>

  <script>
    document.getElementById('year').textContent = new Date().getFullYear();
  </script>
</body>
</html>
